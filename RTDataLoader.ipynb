{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import  numpy as np, pandas as pd, subprocess, os, torch, pickle, csv\n",
    "from nltk.tokenize import word_tokenize as wt\n",
    "from torch import nn\n",
    "from torch.optim import Adam\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchtext.data import Field, Iterator, TabularDataset, BucketIterator\n",
    "from torch.nn.utils.rnn import pad_packed_sequence, pack_padded_sequence\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def get_languages(csv_file, preset):\n",
    "    with open(csv_file, 'r') as csv_File: #opens csv containing language codes and their names\n",
    "        reader = csv.reader(csv_File)\n",
    "        language_table = {row[0].split(';')[1] : row[0].split(';')[0] for row in reader} #dictionary mapping code to name\n",
    "    if preset == 'y':\n",
    "        #Preset language codes to be used in model, chosen at random\n",
    "        language_codes = [\"srd\", \"krc\", \"nob\", \"pnb\",\n",
    "                          \"mai\", \"eng\", \"be-tarask\",\n",
    "                          \"xho\", \"tet\", \"tha\"]\n",
    "        language_names = [(key, value) for key, value in language_table.items() if value in language_codes]\n",
    "        return language_names\n",
    "    elif preset == 'n':\n",
    "        '''\n",
    "        experimental function for allowing user to choose which languages to use\n",
    "        '''\n",
    "        languages = []\n",
    "        while len(languages) != 10:\n",
    "            language = input(\"Enter language \").capitalize()\n",
    "            #print(language)\n",
    "            if language in languages:\n",
    "                print(\"You've already said that one! \")\n",
    "            elif language in language_table:\n",
    "                languages.append(language)\n",
    "                print(languages)\n",
    "            else:\n",
    "                print('Language not recognised. Please refer to language labels')\n",
    "                print(languages)\n",
    "                continue\n",
    "        language_codes = [language_table[i] for i in language_table if i in languages] #collects languages from predetermined set,\n",
    "        language_names =  [(key, value) for key, value in language_table.items() if value in language_codes] #dictionary mapping code to name\n",
    "        return language_names\n",
    "    else:\n",
    "        print(\"has to be y or n dummy\") #in case of user error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def gen_data(training_file, training_labels, language_codes, training):\n",
    "    '''\n",
    "    Function generates the set based on pre defined language codes and creates various\n",
    "    attributes to the object\n",
    "    '''\n",
    "    if training == True:\n",
    "        data = [i.split('\\n')[:-1] for i in open(training_file, 'r')] #opens text file and splits on new line\n",
    "        labels = [i.split('\\n')[:-1] for i in open(training_labels, 'r')] #opens label file and splits on white space\n",
    "        things = list(zip([i[0] for i in data], [i[0] for i in labels])) #zips sentences with corrosponding language label\n",
    "        sets = [(i[0],i[1]) for i in things] #this might actually do the same thing as the above not sure\n",
    "        \n",
    "        x = [i[0][:100] for i in sets if i[1] in language_codes] #Matrix of sentences to be used in the model\n",
    "        y = [i[1] for i in sets if i[1] in language_codes] #labels for each of the sentences\n",
    "        raw_data = ''.join([i for i in x]) #concatenation of all characters in the training set\n",
    "        vocab = {char: ord(char) for char in set(raw_data)} #dictionary mapping character to ord(integer)\n",
    "        int2char = {num : char for char, num in vocab.items()} #dictionary mapping integer to character\n",
    "        return x, y, vocab, int2char\n",
    "    else:\n",
    "        data = [i.split('\\n')[:-1] for i in open(training_file, 'r')] #opens text file and splits on new line\n",
    "        labels = [i.split('\\n')[:-1] for i in open(training_labels, 'r')] #opens label file and splits on white space\n",
    "        things = list(zip([i[0] for i in data], [i[0] for i in labels])) #zips sentences with corrosponding language label\n",
    "        sets = [(i[0],i[1]) for i in things] #this might actually do the same thing as the above not sure\n",
    "        x = [i[0][:100] for i in sets if i[1] in language_codes] #Matrix of sentences to be used in the model\n",
    "        y = [i[1] for i in sets if i[1] in language_codes] #labels for each of the sentences\n",
    "        return x, y\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "language_names = get_languages('./data/raw/labels.csv', 'y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "language_codes = [i[1] for i in language_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = 'data/raw/x_train.txt'\n",
    "y_train = 'data/raw/y_train.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train, vocab, int2char = gen_data(x_train, y_train, language_codes, training=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = 'data/raw/x_test.txt'\n",
    "y_test = 'data/raw/y_test.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test, y_test = gen_data(x_test, y_test, language_codes, training=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def langencoder(language_codes):\n",
    "    one_hot_lang = {}\n",
    "    lang2int = {lang : (num) for num, lang in dict(enumerate(language_codes)).items()}\n",
    "    '''for lang, num in lang2int.items():\n",
    "        one_hot_lang[lang] = np.zeros(9)\n",
    "        one_hot_lang[lang] = np.insert(one_hot_lang[lang],num, 1)\n",
    "        #one_hot_lang[lang] = list([0,0,0,0,0,0,0,0,0,0,0]).insert(num, 1)\n",
    "    '''\n",
    "    #hot2lang = {hot : lang for lang, hot in one_hot_lang.items()}\n",
    "    \n",
    "    return lang2int#, hot2lang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "lang2int = langencoder(language_codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_vocab(x_train):\n",
    "    total_data = ''.join(x_train)\n",
    "    int2char = dict(enumerate(set(total_data)))\n",
    "    char2int = {char : num for num, char in int2char.items() }\n",
    "    #char2int['<niv>'] = max(char2int.values()) +1\n",
    "    return char2int\n",
    "\n",
    "vocab = build_vocab(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_vocab(vocab):\n",
    "    directory = 'vocab/'\n",
    "    if os.path.exists(directory) == False:\n",
    "        os.mkdir(directory)\n",
    "        \n",
    "        \n",
    "    with open('{}vocab.pkl'.format(directory), 'wb') as file:\n",
    "        pickle.dump(vocab, file)\n",
    "        file.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_vocab(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_data(x,y, lang2int,vocab):\n",
    "    labels = []\n",
    "    vectors = []\n",
    "    sets = zip(x,y)\n",
    "    for samples in sets:\n",
    "        \n",
    "        sample = [i for i in samples[0]]\n",
    "        label = samples[1]\n",
    "        #print(label)\n",
    "        count = 100\n",
    "        while count != 0:\n",
    "            #x = [(i,int2label[samples[1]]) for i in samples[0]]\n",
    "            vector = []\n",
    "            encoded = []\n",
    "            for i in sample:\n",
    "                if i in vocab:\n",
    "                    encoded.append(vocab[i])\n",
    "                else:\n",
    "                    encoded.append(random.randint(0,len(vocab)))\n",
    "                \n",
    "            for i in range(1,101):\n",
    "                vectors.append(torch.LongTensor(encoded[:i])) #, int(lang2int[label])))\n",
    "                labels.append(lang2int[label])\n",
    "                count -=1\n",
    "            #vectors += vector\n",
    "            #label_matrix += labels\n",
    "    return pad_sequence(vectors, batch_first=True, padding_value=0), labels\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, train_labels = build_data(x_train, y_train, lang2int, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data, test_labels = build_data(x_test, y_test, lang2int, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RTDataset(Dataset):\n",
    "    def __init__(self, train_x, train_y):\n",
    "        self.train_x = train_x\n",
    "        self.train_y = train_y\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return (self.train_x[index], self.train_y[index])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.train_x)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_set = RTDataset(train_data, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_set = RTDataset(test_data, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_data_set, batch_size=100, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = DataLoader(test_data_set, batch_size=100, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRUNet(nn.Module):\n",
    "    def __init__(self, vocab_size, seq_len, input_size, hidden_size, num_layers, output_size, dev, dropout=0.0):\n",
    "        super().__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.seq_len = seq_len\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.device = device\n",
    "        self.emb = nn.Embedding(vocab_size, input_size).to(device)\n",
    "        self.gru = nn.GRU(input_size, hidden_size,\n",
    "                          num_layers=self.num_layers, batch_first=True, dropout=dropout).to(device)\n",
    "        self.fc = nn.Linear(hidden_size * seq_len, output_size).to(device)\n",
    "        # self.softmax = nn.Softmax(dim=2)\n",
    "\n",
    "    def forward(self, sequence, hidden_layer):\n",
    "        output = self.emb(sequence).to(device)\n",
    "        hidden_layer = hidden_layer.to(self.device)\n",
    "        output, hidden_layer = self.gru(output, hidden_layer)\n",
    "        output = output.contiguous().view(-1, self.hidden_size *\n",
    "                                          len(sequence[0]))\n",
    "        output = self.fc(output).to(device)\n",
    "\n",
    "        return output, hidden_layer\n",
    "    def init_hidden(self, batch_size):\n",
    "        return torch.zeros(self.num_layers, batch_size, self.hidden_size).float().to(self.device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vocab(path):\n",
    "    with open(path+'vocab.pkl', 'rb')as file:\n",
    "        vocab = pickle.load(file)\n",
    "    return vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'def get_dataloaders(filepath):\\n    dataloaders = []\\n    for i in os.listdir(filepath):\\n        if i == \\'.ipynb_checkpoints\\':\\n            continue\\n        with open(filepath + i, \"rb\") as input_file:\\n            dataloaders.append(pickle.load(input_file))\\n            input_file.close()\\n    return dataloaders[0], dataloaders[1]\\n\\ndef train(training_dataloader, model):\\n    pass\\n\\n\\ntrain_loader, test_loader = get_dataloaders(\\'dataloaders/\\')'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''def get_dataloaders(filepath):\n",
    "    dataloaders = []\n",
    "    for i in os.listdir(filepath):\n",
    "        if i == '.ipynb_checkpoints':\n",
    "            continue\n",
    "        with open(filepath + i, \"rb\") as input_file:\n",
    "            dataloaders.append(pickle.load(input_file))\n",
    "            input_file.close()\n",
    "    return dataloaders[0], dataloaders[1]\n",
    "\n",
    "def train(training_dataloader, model):\n",
    "    pass\n",
    "\n",
    "\n",
    "train_loader, test_loader = get_dataloaders('dataloaders/')'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = get_vocab('vocab/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(vocab)\n",
    "sequence = 100\n",
    "batch_size = 100\n",
    "input_size = 100\n",
    "hidden_size = 256\n",
    "nr_layers = 2\n",
    "output_size = 10\n",
    "device = torch.device('cuda:0')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GRUNet(vocab_size, sequence, input_size, \n",
    "               hidden_size, nr_layers, output_size, device, dropout=0.0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GRUNet(\n",
       "  (emb): Embedding(879, 100)\n",
       "  (gru): GRU(100, 256, num_layers=2, batch_first=True)\n",
       "  (fc): Linear(in_features=25600, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4d48dd29c7d4d2ab59c153f4bdc0dd3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=20), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb63683b4ab841f3a7b905ab0ff446a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss at epoch 1: 0.0845533\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d59048eff3ab4e60b4888efa9dfee5be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss at epoch 2: 0.0543851\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9b8bfbbb46b4ea8a1c92606f6a5d59a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss at epoch 3: 0.0845897\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d337de0c03634209850ab60710a438b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss at epoch 4: 0.0557049\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64ef1e0a1f6143cc9ea72083074d2b86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss at epoch 5: 0.0458393\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de49281ad94143059f72a48090726448",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss at epoch 6: 0.0744213\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bdfb1afbb5a47e7b582a3bc28473231",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss at epoch 7: 0.2028613\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3e89ab61fa847fb9fe9d17541373757",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss at epoch 8: 0.4564747\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b735bd4ca1e54b3388e0cea9aa9c3172",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss at epoch 9: 0.4002304\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "846a83bfb5424d33bb6fb7d7c0a9a185",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss at epoch 10: 0.4465500\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0728fd22e95d40109b99095e8c5121a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss at epoch 11: 0.4379047\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5cc6f238c80c4658b522ff3d87ac2f32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss at epoch 12: 0.4698699\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3558a72ea4e46ed9f2c526ef3af4c81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss at epoch 13: 0.4770084\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa7f6089a33441a3acabebeb9eb9e6ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss at epoch 14: 0.4945874\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a80452b6cfdf441f906039840743b217",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss at epoch 15: 0.4728319\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4add4da767c24264a03ab2e465309033",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss at epoch 16: 0.5613053\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3797cacd46c14ba6957b5c9254da5ed0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss at epoch 17: 0.5397002\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d412de4d7d724247a6899268c62f10bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss at epoch 18: 0.5576397\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2b79299677e48f9bc9b80485d948346",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss at epoch 19: 0.5606002\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b8b38aef97a4646a3896e8c020c3638",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss at epoch 20: 0.5960788\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "model = model.to(device)\n",
    "print('Training')\n",
    "epoch_nr = 0\n",
    "EPOCH = list(range(20))\n",
    "for epoch in tqdm(EPOCH):\n",
    "    epoch_nr += 1\n",
    "    epoch_loss = []\n",
    "    h = model.init_hidden(batch_size)\n",
    "    count = 0\n",
    "\n",
    "    percent = 10\n",
    "    with tqdm(total=len(train_loader)) as pbar:\n",
    "        for (x,y) in train_loader:\n",
    "        \n",
    "            count +=1 \n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            h = h.data\n",
    "            out, h = model(x, h)\n",
    "            loss = criterion(out, y.long())\n",
    "            loss.backward()\n",
    "            epoch_loss.append(loss.item())\n",
    "            optimizer.step()\n",
    "            #print('Loss per timestep = {}'.format(loss.item()))\n",
    "            pbar.update(1)\n",
    "            \n",
    "        avg_loss = sum(epoch_loss) / len(epoch_loss)\n",
    "        print(\"Average loss at epoch %d: %.7f\" % (epoch_nr, avg_loss)) \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_model = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(trained_model, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, model_nr):\n",
    "    directory = 'trained_models/'\n",
    "    if os.path.exists(directory) == False:\n",
    "        os.mkdir(directory)\n",
    "        \n",
    "    torch.save(model.state_dict(), '{}gru_model_nr{}.pt'.format(directory,model_nr))\n",
    "        \n",
    "def load_model(path):\n",
    "    model = os.listdir(path)[2]\n",
    "    print(model)\n",
    "    with open(path+model, 'rb') as input_model:\n",
    "        print(input_model)\n",
    "        trained_model = torch.load(input_model)\n",
    "        \n",
    "        \n",
    "    return trained_model\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gru_model_nr2.pt\n",
      "<_io.BufferedReader name='trained_models/gru_model_nr2.pt'>\n"
     ]
    }
   ],
   "source": [
    "dp = load_model('trained_models/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_model = GRUNet(vocab_size, sequence, input_size, \n",
    "               hidden_size, nr_layers, output_size, device, dropout=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for GRUNet:\n\tUnexpected key(s) in state_dict: \"gru.weight_ih_l2\", \"gru.weight_hh_l2\", \"gru.bias_ih_l2\", \"gru.bias_hh_l2\". \n\tsize mismatch for gru.weight_ih_l0: copying a param with shape torch.Size([600, 100]) from checkpoint, the shape in current model is torch.Size([768, 100]).\n\tsize mismatch for gru.weight_hh_l0: copying a param with shape torch.Size([600, 200]) from checkpoint, the shape in current model is torch.Size([768, 256]).\n\tsize mismatch for gru.bias_ih_l0: copying a param with shape torch.Size([600]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for gru.bias_hh_l0: copying a param with shape torch.Size([600]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for gru.weight_ih_l1: copying a param with shape torch.Size([600, 200]) from checkpoint, the shape in current model is torch.Size([768, 256]).\n\tsize mismatch for gru.weight_hh_l1: copying a param with shape torch.Size([600, 200]) from checkpoint, the shape in current model is torch.Size([768, 256]).\n\tsize mismatch for gru.bias_ih_l1: copying a param with shape torch.Size([600]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for gru.bias_hh_l1: copying a param with shape torch.Size([600]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for fc.weight: copying a param with shape torch.Size([10, 20000]) from checkpoint, the shape in current model is torch.Size([10, 25600]).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-83-5510f33709b1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrained_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib64/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m    843\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    844\u001b[0m             raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n\u001b[0;32m--> 845\u001b[0;31m                                self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n\u001b[0m\u001b[1;32m    846\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_IncompatibleKeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmissing_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munexpected_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    847\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for GRUNet:\n\tUnexpected key(s) in state_dict: \"gru.weight_ih_l2\", \"gru.weight_hh_l2\", \"gru.bias_ih_l2\", \"gru.bias_hh_l2\". \n\tsize mismatch for gru.weight_ih_l0: copying a param with shape torch.Size([600, 100]) from checkpoint, the shape in current model is torch.Size([768, 100]).\n\tsize mismatch for gru.weight_hh_l0: copying a param with shape torch.Size([600, 200]) from checkpoint, the shape in current model is torch.Size([768, 256]).\n\tsize mismatch for gru.bias_ih_l0: copying a param with shape torch.Size([600]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for gru.bias_hh_l0: copying a param with shape torch.Size([600]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for gru.weight_ih_l1: copying a param with shape torch.Size([600, 200]) from checkpoint, the shape in current model is torch.Size([768, 256]).\n\tsize mismatch for gru.weight_hh_l1: copying a param with shape torch.Size([600, 200]) from checkpoint, the shape in current model is torch.Size([768, 256]).\n\tsize mismatch for gru.bias_ih_l1: copying a param with shape torch.Size([600]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for gru.bias_hh_l1: copying a param with shape torch.Size([600]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for fc.weight: copying a param with shape torch.Size([10, 20000]) from checkpoint, the shape in current model is torch.Size([10, 25600])."
     ]
    }
   ],
   "source": [
    "trained_model.load_state_dict(dp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "tqdm().pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'eng': 0,\n",
       " 'be-tarask': 1,\n",
       " 'krc': 2,\n",
       " 'mai': 3,\n",
       " 'nob': 4,\n",
       " 'pnb': 5,\n",
       " 'srd': 6,\n",
       " 'tet': 7,\n",
       " 'tha': 8,\n",
       " 'xho': 9}"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lang2int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7af71438a7524efcb5f5c849ad5f61c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "predictions = []\n",
    "correct = []\n",
    "correct = 0\n",
    "correct_map = {}\n",
    "count = 0\n",
    "batch_nr = 1\n",
    "with tqdm(total=len(test_loader)) as pbar:\n",
    "    for batch in test_loader:\n",
    "        batch_nr += 1\n",
    "        hidden_layer = model.init_hidden(1).to(device)\n",
    "        for i ,examples in enumerate(zip(batch[0], batch[1])):\n",
    "            prediction = trained_model(examples[0].unsqueeze(0).to(device), hidden_layer)\n",
    "            _, indeces = torch.max(prediction[0].data, dim=1)\n",
    "            #predictions.append(indices[0].item())\n",
    "            \n",
    "            if indeces[0].item() == examples[1].item():\n",
    "                \n",
    "                correct += 1\n",
    "            count += 1\n",
    "        pbar.update(1)\n",
    "    print('Accuracy after batch {}: {}'.format(batch_nr, ((correct / count) * 100)))\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "440730"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88.146"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct / 500000 * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
