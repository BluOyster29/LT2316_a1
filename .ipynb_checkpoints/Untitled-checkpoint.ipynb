{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, torch, pickle, torch, config\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from LangIdentDataset import RTDataset \n",
    "import stats\n",
    "from GRUNetwork import RNN_GRU\n",
    "import get_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv, os, argparse\n",
    "import config\n",
    "\n",
    "def get_args():\n",
    "    parser = argparse.ArgumentParser(\n",
    "        description=\"\")\n",
    "    parser.add_argument(\"-P\", \"--preset\", dest='preset', type=str,\n",
    "                        help=\"Choose to use default language set or your own\", default=\"y\")\n",
    "\n",
    "    parser.add_argument(\"-F\", \"--Folder\", dest='folder', type=str, default=\"data/raw/\",\n",
    "                        help=\"Directory that contains training data\")\n",
    "    args = parser.parse_args()\n",
    "    return args\n",
    "\n",
    "def get_files_from_folder(folder):\n",
    "    files = os.listdir(folder)\n",
    "\n",
    "    return folder+files[0], folder+files[1], folder+files[2], folder+files[3], folder+files[4]\n",
    "\n",
    "def get_languages(csv_file, preset):\n",
    "    with open(csv_file, 'r') as csv_File: #opens csv containing language codes and their names\n",
    "        reader = csv.reader(csv_File)\n",
    "        language_table = {row[0].split(';')[1] : row[0].split(';')[0] for row in reader} #dictionary mapping code to name\n",
    "    if preset == 'y':\n",
    "        #Preset language codes to be used in model, chosen at random\n",
    "        language_codes = [\"srd\", \"krc\", \"nob\", \"pnb\",\n",
    "                          \"mai\", \"eng\", \"be-tarask\",\n",
    "                          \"xho\", \"tet\", \"tha\"]\n",
    "        language_names = [(key, value) for key, value in language_table.items() if value in language_codes]\n",
    "        return language_names\n",
    "    elif preset == 'n':\n",
    "        '''\n",
    "        experimental function for allowing user to choose which languages to use\n",
    "        '''\n",
    "        languages = []\n",
    "        while len(languages) != 10:\n",
    "            language = input(\"Enter language \").capitalize()\n",
    "            #print(language)\n",
    "            if language in languages:\n",
    "                print(\"You've already said that one! \")\n",
    "            elif language in language_table:\n",
    "                languages.append(language)\n",
    "                print(' '.join(languages))\n",
    "            else:\n",
    "                print('Language not recognised. Please refer to language labels')\n",
    "                print(' '.join(languages))\n",
    "                continue\n",
    "        language_codes = [language_table[i] for i in language_table if i in languages] #collects languages from predetermined set,\n",
    "        language_names =  [(key, value) for key, value in language_table.items() if value in language_codes] #dictionary mapping code to name\n",
    "        return language_names\n",
    "    else:\n",
    "        print(\"has to be y or n dummy\") #in case of user error\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def langencoder(language_codes):\n",
    "    one_hot_lang = {}\n",
    "    lang2int = {lang : (num) for num, lang in dict(enumerate(language_codes)).items()}\n",
    "  \n",
    "    return lang2int\n",
    "\n",
    "def load_model(path, config):\n",
    "    model = os.listdir(path)[0]\n",
    "    if config['device'] == 'gpu':\n",
    "        device = torch.device('cuda:01')\n",
    "    else:\n",
    "        device = torch.device('cpu')\n",
    "    print(model)\n",
    "    with open(path+model, 'rb') as input_model:\n",
    "        data = torch.load(input_model)\n",
    "    trained_model = RNN_GRU(vocab_size=config['vocab_size'], seq_len=100, input_size=100, \n",
    "               hidden_size=256, num_layers=2, output_size=10, device=device, dropout=0.0)\n",
    "    trained_model.load_state_dict(data)    \n",
    "    return trained_model\n",
    "\n",
    "def get_vocab(path):\n",
    "    with open(path+'vocab.pkl', 'rb')as file:\n",
    "        vocab = pickle.load(file)\n",
    "    return vocab\n",
    "\n",
    "def get_test_loader(path):\n",
    "    loaders = os.listdir(path)\n",
    "    print(loaders)\n",
    "    with open(path+loaders[0], 'rb') as file:\n",
    "        testing_loader = pickle.load(file)\n",
    "    \n",
    "    return testing_loader\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = trained_model.init_hidden(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 100, 256])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gru_model_100batches_10epochs.pt\n",
      "['training_loader.pkl', 'test_dataset.pkl']\n"
     ]
    }
   ],
   "source": [
    "CONFIG = config.get_config('config/config.json')\n",
    "if CONFIG['device'] == 'cpu':\n",
    "    device = torch.device('cpu')\n",
    "else:\n",
    "    device = 'cuda:01'\n",
    "language_codes = [i[1] for i in CONFIG['languages']]\n",
    "language_names = CONFIG['languages']\n",
    "lang2int = langencoder(language_codes)\n",
    "int2lang = {num : lang for lang, num in lang2int.items()}\n",
    "vocab = get_vocab('vocab/')\n",
    "trained_model = load_model('trained_models/', CONFIG).to(device)\n",
    "test_data = get_test_loader('dataloaders/')\n",
    "language_names_dict = {i[1] : i[0] for i in language_names}\n",
    "language_stats = stats.gen_empty_stats(int2lang, language_names_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "print(len(test_data))\n",
    "for i in test_data:\n",
    "    print(len(i[0]))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(trained_model, test_data, language_stats, device, language_names_dict):\n",
    "    correct_per_example = 0\n",
    "    total_predictions = 5000\n",
    "    percent = 0\n",
    "    batch_nr = 1\n",
    "    tenp = 500\n",
    "    num_characters = []\n",
    "    count = 0\n",
    "    for x, y in test_data:\n",
    "        batch_nr +=1\n",
    "        \n",
    "        hidden_layer = trained_model.init_hidden(1).to(device)\n",
    "        for examples in zip(x,y):\n",
    "            #total_predictions += 1\n",
    "            count += 1\n",
    "            prediction = trained_model(examples[0].unsqueeze(0).to(device), hidden_layer)\n",
    "            _, indeces = torch.max(prediction[0].data, dim=1)\n",
    "            characters = len(torch.nonzero(examples[0]))\n",
    "            stats.update_stats(language_stats, indeces[0].item(), examples[1].item(), int2lang, characters, language_names_dict)\n",
    "            \n",
    "            if indeces[0].item() == examples[1].item():\n",
    "                num_characters.append(characters)\n",
    "                correct_per_example += 1\n",
    "                break\n",
    "            else:\n",
    "                continue\n",
    "                \n",
    "        if count % tenp == 0:\n",
    "            percent += 10\n",
    "            print('Accuracy after {}% tested: {}'.format(percent, (correct / total_predictions * 100)))\n",
    "    return language_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([446,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0]), tensor(9))\n"
     ]
    }
   ],
   "source": [
    "language_stats = test_model(trained_model, test_data, language_stats, device, language_names_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG = config.get_config('config/config.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['English', 'eng'],\n",
       " ['Belarusian (Taraschkewiza)', 'be-tarask'],\n",
       " ['Karachay-Balkar', 'krc'],\n",
       " ['Maithili', 'mai'],\n",
       " ['Bokm책l', 'nob'],\n",
       " ['Western Panjabi', 'pnb'],\n",
       " ['Sardinian', 'srd'],\n",
       " ['Tetum', 'tet'],\n",
       " ['Thai', 'tha'],\n",
       " ['Xhosa', 'xho']]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "language_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "languages = [i[0] for i in language_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def further_analysis(language_stats, language_names ,int2lang):\n",
    "    \n",
    "    for i in languages:\n",
    "        lang_guessed = [i[0] for i in languages]\n",
    "    \n",
    "        lang_guessed = dict(Counter([int2lang[x] for x in language_stats[i]['languages_guessed']]))\n",
    "        x = [(value,key) for key, value in lang_guessed.items()]\n",
    "        sec_max = sorted(x)[-2][1]\n",
    "        las = sorted(x)[0][1]\n",
    "        num_char = language_stats[i]['num_characters']\n",
    "        avg_char = sum(num_char) / len(num_char)\n",
    "        print('Language: {}'.format(i))\n",
    "        print('Total guesses: {}'.format(language_stats[i]['total_guesses']))\n",
    "        print('Total correct: {}'.format(language_stats[i]['correct_guesses']))\n",
    "        print('Total accuracy for {}: {}%'.format(i,str(round(language_stats[i]['correct_guesses']/ language_stats[i]['total_guesses'] * 100,2))))\n",
    "        print('Languages Guessed: {}'.format(dict(Counter(lang_guessed))))\n",
    "        print('Most incorrectly guessed: {}'.format(sec_max))\n",
    "        print('Least incorrectly guessed: {}'.format(las))\n",
    "        print('Average characters until correct guess: {}'.format(avg_char))\n",
    "        print('\\n')\n",
    "        '''data = {'language'      : i, \n",
    "                'total_guesses' : language_stats[i]['total guesses'],\n",
    "                'total_correct' : language_stats[i]['correct guesses'],\n",
    "                'accuracy'      :  str(round(language_stats[i]['correct guesses']/ language_stats[i]['total guesses'] * 100,2)),\n",
    "                'languages_guessed' : dict(Counter(lang_guessed))}'''\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English\n",
      "500\n",
      "Language: English\n",
      "Total guesses: 581\n",
      "Total correct: 500\n",
      "Total accuracy for English: 86.06%\n",
      "Languages Guessed: {'eng': 500, 'be-tarask': 19, 'tha': 15, 'mai': 7, 'krc': 9, 'nob': 1, 'tet': 30}\n",
      "Most incorrectly guessed: tet\n",
      "Least incorrectly guessed: nob\n",
      "Average characters until correct guess: 1.162\n",
      "\n",
      "\n",
      "Belarusian (Taraschkewiza)\n",
      "500\n",
      "Language: Belarusian (Taraschkewiza)\n",
      "Total guesses: 536\n",
      "Total correct: 500\n",
      "Total accuracy for Belarusian (Taraschkewiza): 93.28%\n",
      "Languages Guessed: {'be-tarask': 500, 'tet': 9, 'mai': 2, 'eng': 13, 'tha': 10, 'krc': 1, 'nob': 1}\n",
      "Most incorrectly guessed: eng\n",
      "Least incorrectly guessed: krc\n",
      "Average characters until correct guess: 1.072\n",
      "\n",
      "\n",
      "Karachay-Balkar\n",
      "500\n",
      "Language: Karachay-Balkar\n",
      "Total guesses: 1721\n",
      "Total correct: 500\n",
      "Total accuracy for Karachay-Balkar: 29.05%\n",
      "Languages Guessed: {'tha': 241, 'mai': 138, 'tet': 229, 'krc': 500, 'eng': 527, 'be-tarask': 75, 'nob': 3, 'xho': 6, 'pnb': 2}\n",
      "Most incorrectly guessed: krc\n",
      "Least incorrectly guessed: pnb\n",
      "Average characters until correct guess: 3.442\n",
      "\n",
      "\n",
      "Maithili\n",
      "500\n",
      "Language: Maithili\n",
      "Total guesses: 1755\n",
      "Total correct: 500\n",
      "Total accuracy for Maithili: 28.49%\n",
      "Languages Guessed: {'tet': 227, 'mai': 500, 'tha': 311, 'eng': 575, 'be-tarask': 69, 'krc': 64, 'pnb': 1, 'xho': 3, 'nob': 2, 'srd': 3}\n",
      "Most incorrectly guessed: mai\n",
      "Least incorrectly guessed: pnb\n",
      "Average characters until correct guess: 3.51\n",
      "\n",
      "\n",
      "Bokm책l\n",
      "500\n",
      "Language: Bokm책l\n",
      "Total guesses: 677\n",
      "Total correct: 500\n",
      "Total accuracy for Bokm책l: 73.86%\n",
      "Languages Guessed: {'nob': 500, 'xho': 119, 'eng': 11, 'tha': 12, 'tet': 6, 'be-tarask': 4, 'srd': 21, 'mai': 4}\n",
      "Most incorrectly guessed: xho\n",
      "Least incorrectly guessed: be-tarask\n",
      "Average characters until correct guess: 1.354\n",
      "\n",
      "\n",
      "Western Panjabi\n",
      "500\n",
      "Language: Western Panjabi\n",
      "Total guesses: 531\n",
      "Total correct: 500\n",
      "Total accuracy for Western Panjabi: 94.16%\n",
      "Languages Guessed: {'pnb': 500, 'eng': 8, 'xho': 2, 'tha': 3, 'tet': 8, 'be-tarask': 9, 'nob': 1}\n",
      "Most incorrectly guessed: be-tarask\n",
      "Least incorrectly guessed: nob\n",
      "Average characters until correct guess: 1.062\n",
      "\n",
      "\n",
      "Sardinian\n",
      "500\n",
      "Language: Sardinian\n",
      "Total guesses: 563\n",
      "Total correct: 500\n",
      "Total accuracy for Sardinian: 88.81%\n",
      "Languages Guessed: {'srd': 500, 'xho': 47, 'eng': 6, 'be-tarask': 4, 'nob': 4, 'tet': 1, 'tha': 1}\n",
      "Most incorrectly guessed: xho\n",
      "Least incorrectly guessed: tet\n",
      "Average characters until correct guess: 1.126\n",
      "\n",
      "\n",
      "Tetum\n",
      "500\n",
      "Language: Tetum\n",
      "Total guesses: 1206\n",
      "Total correct: 500\n",
      "Total accuracy for Tetum: 41.46%\n",
      "Languages Guessed: {'eng': 405, 'tet': 500, 'tha': 136, 'be-tarask': 101, 'krc': 29, 'mai': 20, 'xho': 4, 'nob': 7, 'pnb': 2, 'srd': 2}\n",
      "Most incorrectly guessed: eng\n",
      "Least incorrectly guessed: pnb\n",
      "Average characters until correct guess: 2.412\n",
      "\n",
      "\n",
      "Thai\n",
      "500\n",
      "Language: Thai\n",
      "Total guesses: 1307\n",
      "Total correct: 500\n",
      "Total accuracy for Thai: 38.26%\n",
      "Languages Guessed: {'tha': 500, 'eng': 375, 'tet': 269, 'xho': 17, 'krc': 58, 'be-tarask': 48, 'mai': 32, 'nob': 3, 'srd': 5}\n",
      "Most incorrectly guessed: eng\n",
      "Least incorrectly guessed: nob\n",
      "Average characters until correct guess: 2.614\n",
      "\n",
      "\n",
      "Xhosa\n",
      "500\n",
      "Language: Xhosa\n",
      "Total guesses: 1004\n",
      "Total correct: 500\n",
      "Total accuracy for Xhosa: 49.8%\n",
      "Languages Guessed: {'nob': 434, 'xho': 500, 'tha': 11, 'eng': 23, 'srd': 27, 'be-tarask': 6, 'krc': 1, 'tet': 1, 'mai': 1}\n",
      "Most incorrectly guessed: nob\n",
      "Least incorrectly guessed: krc\n",
      "Average characters until correct guess: 2.008\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "further_analysis(language_stats, language_names, int2lang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'num_characters' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-96-d43ceb374e42>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnum_characters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'num_characters' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
