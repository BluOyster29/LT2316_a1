{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, torch, pickle, torch, config\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from LangIdentDataset import RTDataset \n",
    "import stats\n",
    "from GRUNetwork import RNN_GRU\n",
    "import get_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv, os, argparse\n",
    "import config\n",
    "\n",
    "def get_args():\n",
    "    parser = argparse.ArgumentParser(\n",
    "        description=\"\")\n",
    "    parser.add_argument(\"-P\", \"--preset\", dest='preset', type=str,\n",
    "                        help=\"Choose to use default language set or your own\", default=\"y\")\n",
    "\n",
    "    parser.add_argument(\"-F\", \"--Folder\", dest='folder', type=str, default=\"data/raw/\",\n",
    "                        help=\"Directory that contains training data\")\n",
    "    args = parser.parse_args()\n",
    "    return args\n",
    "\n",
    "def get_files_from_folder(folder):\n",
    "    files = os.listdir(folder)\n",
    "\n",
    "    return folder+files[0], folder+files[1], folder+files[2], folder+files[3], folder+files[4]\n",
    "\n",
    "def get_languages(csv_file, preset):\n",
    "    with open(csv_file, 'r') as csv_File: #opens csv containing language codes and their names\n",
    "        reader = csv.reader(csv_File)\n",
    "        language_table = {row[0].split(';')[1] : row[0].split(';')[0] for row in reader} #dictionary mapping code to name\n",
    "    if preset == 'y':\n",
    "        #Preset language codes to be used in model, chosen at random\n",
    "        language_codes = [\"srd\", \"krc\", \"nob\", \"pnb\",\n",
    "                          \"mai\", \"eng\", \"be-tarask\",\n",
    "                          \"xho\", \"tet\", \"tha\"]\n",
    "        language_names = [(key, value) for key, value in language_table.items() if value in language_codes]\n",
    "        return language_names\n",
    "    elif preset == 'n':\n",
    "        '''\n",
    "        experimental function for allowing user to choose which languages to use\n",
    "        '''\n",
    "        languages = []\n",
    "        while len(languages) != 10:\n",
    "            language = input(\"Enter language \").capitalize()\n",
    "            #print(language)\n",
    "            if language in languages:\n",
    "                print(\"You've already said that one! \")\n",
    "            elif language in language_table:\n",
    "                languages.append(language)\n",
    "                print(' '.join(languages))\n",
    "            else:\n",
    "                print('Language not recognised. Please refer to language labels')\n",
    "                print(' '.join(languages))\n",
    "                continue\n",
    "        language_codes = [language_table[i] for i in language_table if i in languages] #collects languages from predetermined set,\n",
    "        language_names =  [(key, value) for key, value in language_table.items() if value in language_codes] #dictionary mapping code to name\n",
    "        return language_names\n",
    "    else:\n",
    "        print(\"has to be y or n dummy\") #in case of user error\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def langencoder(language_codes):\n",
    "    one_hot_lang = {}\n",
    "    lang2int = {lang : (num) for num, lang in dict(enumerate(language_codes)).items()}\n",
    "  \n",
    "    return lang2int\n",
    "\n",
    "def load_model(path, config):\n",
    "    model = os.listdir(path)[0]\n",
    "    if config['device'] == 'gpu':\n",
    "        device = torch.device('cuda:01')\n",
    "    else:\n",
    "        device = torch.device('cpu')\n",
    "    print(model)\n",
    "    with open(path+model, 'rb') as input_model:\n",
    "        data = torch.load(input_model)\n",
    "    trained_model = RNN_GRU(vocab_size=config['vocab_size'], seq_len=100, input_size=100, \n",
    "               hidden_size=256, num_layers=2, output_size=10, device=device, dropout=0.0)\n",
    "    trained_model.load_state_dict(data)    \n",
    "    return trained_model\n",
    "\n",
    "def get_vocab(path):\n",
    "    with open(path+'vocab.pkl', 'rb')as file:\n",
    "        vocab = pickle.load(file)\n",
    "    return vocab\n",
    "\n",
    "def get_test_loader(path):\n",
    "    loaders = os.listdir(path)\n",
    "    print(loaders)\n",
    "    with open(path+loaders[1], 'rb') as file:\n",
    "        testing_loader = pickle.load(file)\n",
    "    \n",
    "    return testing_loader\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gru_model_100batches_10epochs.pt\n",
      "['training_loader.pkl', 'test_dataset.pkl']\n"
     ]
    }
   ],
   "source": [
    "CONFIG = config.get_config('config/config.json')\n",
    "if CONFIG['device'] == 'cpu':\n",
    "    device = torch.device('cpu')\n",
    "else:\n",
    "    device = 'cuda:01'\n",
    "language_codes = [i[1] for i in CONFIG['languages']]\n",
    "language_names = CONFIG['languages']\n",
    "lang2int = langencoder(language_codes)\n",
    "int2lang = {num : lang for lang, num in lang2int.items()}\n",
    "vocab = get_vocab('vocab/')\n",
    "trained_model = load_model('trained_models/', CONFIG).to(device)\n",
    "test_data = get_test_loader('dataloaders/')\n",
    "language_names_dict = {i[1] : i[0] for i in language_names}\n",
    "language_stats = stats.gen_empty_stats(int2lang, language_names_dict)\n",
    "languages = [i[0] for i in language_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(trained_model, test_data, language_stats, device, language_names_dict):\n",
    "    correct_per_example = 0\n",
    "    incorrect_guesses_per_instance = 0\n",
    "    percent = 0\n",
    "    example = 0\n",
    "    batch_nr = 0\n",
    "    tenp = 500\n",
    "    num_characters = []\n",
    "    count = 0\n",
    "    for x, y in test_data:\n",
    "        count += 1\n",
    "        batch_nr +=1\n",
    "        example +=1\n",
    "        hidden_layer = trained_model.init_hidden(1).to(device)\n",
    "        for examples in zip(x,y):\n",
    "            #total_predictions += 1\n",
    "            \n",
    "            prediction = trained_model(examples[0].unsqueeze(0).to(device), hidden_layer)\n",
    "            _, indeces = torch.max(prediction[0].data, dim=1)\n",
    "            characters = len(torch.nonzero(examples[0]))\n",
    "            \n",
    "            \n",
    "            if indeces[0].item() == examples[1].item():\n",
    "                num_characters.append(characters)\n",
    "                correct_per_example += 1\n",
    "                stats.update_stats(language_stats, indeces[0].item(), examples[1].item(), int2lang, characters, language_names_dict)\n",
    "                break\n",
    "            else:\n",
    "                characters = 0\n",
    "                stats.update_stats(language_stats, indeces[0].item(), examples[1].item(), int2lang, characters, language_names_dict)\n",
    "                incorrect_guesses_per_instance += 1\n",
    "                continue\n",
    "                \n",
    "        if count % tenp == 0:\n",
    "            percent += 10\n",
    "            print('Accuracy after {}% tested: {}'.format(percent, (correct_per_example / example * 100)))\n",
    "    \n",
    "    return language_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy after 10% tested: 100.0\n",
      "Accuracy after 20% tested: 100.0\n",
      "Accuracy after 30% tested: 100.0\n",
      "Accuracy after 40% tested: 100.0\n",
      "Accuracy after 50% tested: 100.0\n",
      "Accuracy after 60% tested: 100.0\n",
      "Accuracy after 70% tested: 100.0\n",
      "Accuracy after 80% tested: 100.0\n",
      "Accuracy after 90% tested: 100.0\n",
      "Accuracy after 100% tested: 100.0\n"
     ]
    }
   ],
   "source": [
    "language_stats = test_model(trained_model, test_data, language_stats, device, language_names_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "def further_analysis(language_stats, language_names ,int2lang, language_names_dict):\n",
    "    \n",
    "    for i in languages:\n",
    "        lang_guessed = [i[0] for i in languages]\n",
    "    \n",
    "        lang_guessed = dict(Counter([language_names_dict[int2lang[x]] for x in language_stats[i]['languages_guessed']]))\n",
    "        x = [(value,key) for key, value in lang_guessed.items()]\n",
    "        sec_max = sorted(x)[-2][1]\n",
    "        las = sorted(x)[0][1]\n",
    "        num_char = language_stats[i]['num_characters']\n",
    "        \n",
    "        avg_char = sum(num_char) / len(num_char)\n",
    "        print('Language: {}'.format(i))\n",
    "        print('Total guesses: {}'.format(language_stats[i]['total_guesses']))\n",
    "        print('Total correct: {}'.format(language_stats[i]['correct_guesses']))\n",
    "        print('Total accuracy for {}: {}%'.format(i,str(round(language_stats[i]['correct_guesses']/ language_stats[i]['total_guesses'] * 100,2))))\n",
    "        print('Languages Guessed: {}'.format(dict(Counter(lang_guessed))))\n",
    "        print('Most incorrectly guessed: {}'.format(sec_max))\n",
    "        print('Least incorrectly guessed: {}'.format(las))\n",
    "        print('Average characters until correct guess: {}'.format(avg_char))\n",
    "        print('\\n')\n",
    "        '''data = {'language'      : i, \n",
    "                'total_guesses' : language_stats[i]['total guesses'],\n",
    "                'total_correct' : language_stats[i]['correct guesses'],\n",
    "                'accuracy'      :  str(round(language_stats[i]['correct guesses']/ language_stats[i]['total guesses'] * 100,2)),\n",
    "                'languages_guessed' : dict(Counter(lang_guessed))}'''\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Language: English\n",
      "Total guesses: 1295\n",
      "Total correct: 500\n",
      "Total accuracy for English: 38.61%\n",
      "Languages Guessed: {'Lithuanian': 643, 'English': 500, 'Serbian': 25, 'Polish': 21, 'Ukrainian': 10, 'Slovene': 21, 'Russian': 46, 'Slovak': 10, 'Croatian': 19}\n",
      "Most incorrectly guessed: English\n",
      "Least incorrectly guessed: Slovak\n",
      "Average characters until correct guess: 2.578\n",
      "\n",
      "\n",
      "Language: Czech\n",
      "Total guesses: 3372\n",
      "Total correct: 500\n",
      "Total accuracy for Czech: 14.83%\n",
      "Languages Guessed: {'Croatian': 969, 'Serbian': 1065, 'Slovak': 274, 'Czech': 500, 'Polish': 188, 'Lithuanian': 126, 'Ukrainian': 111, 'Russian': 3, 'Slovene': 122, 'English': 14}\n",
      "Most incorrectly guessed: Croatian\n",
      "Least incorrectly guessed: Russian\n",
      "Average characters until correct guess: 6.744\n",
      "\n",
      "\n",
      "Language: Croatian\n",
      "Total guesses: 984\n",
      "Total correct: 500\n",
      "Total accuracy for Croatian: 50.81%\n",
      "Languages Guessed: {'Croatian': 500, 'Slovene': 54, 'Serbian': 263, 'Lithuanian': 56, 'Slovak': 21, 'Polish': 59, 'Czech': 5, 'Ukrainian': 22, 'Russian': 2, 'English': 2}\n",
      "Most incorrectly guessed: Serbian\n",
      "Least incorrectly guessed: English\n",
      "Average characters until correct guess: 1.968\n",
      "\n",
      "\n",
      "Language: Lithuanian\n",
      "Total guesses: 743\n",
      "Total correct: 500\n",
      "Total accuracy for Lithuanian: 67.29%\n",
      "Languages Guessed: {'English': 166, 'Lithuanian': 500, 'Serbian': 9, 'Russian': 14, 'Croatian': 19, 'Slovak': 2, 'Slovene': 24, 'Polish': 4, 'Ukrainian': 4, 'Czech': 1}\n",
      "Most incorrectly guessed: English\n",
      "Least incorrectly guessed: Czech\n",
      "Average characters until correct guess: 1.48\n",
      "\n",
      "\n",
      "Language: Polish\n",
      "Total guesses: 1959\n",
      "Total correct: 500\n",
      "Total accuracy for Polish: 25.52%\n",
      "Languages Guessed: {'Polish': 500, 'Serbian': 501, 'Croatian': 505, 'Slovak': 160, 'Ukrainian': 52, 'Lithuanian': 144, 'Slovene': 61, 'Czech': 17, 'English': 17, 'Russian': 2}\n",
      "Most incorrectly guessed: Serbian\n",
      "Least incorrectly guessed: Russian\n",
      "Average characters until correct guess: 3.918\n",
      "\n",
      "\n",
      "Language: Russian\n",
      "Total guesses: 2452\n",
      "Total correct: 500\n",
      "Total accuracy for Russian: 20.39%\n",
      "Languages Guessed: {'Lithuanian': 1243, 'Russian': 500, 'English': 361, 'Croatian': 153, 'Ukrainian': 41, 'Serbian': 94, 'Slovak': 27, 'Polish': 26, 'Slovene': 4, 'Czech': 3}\n",
      "Most incorrectly guessed: Russian\n",
      "Least incorrectly guessed: Czech\n",
      "Average characters until correct guess: 4.876\n",
      "\n",
      "\n",
      "Language: Slovak\n",
      "Total guesses: 2436\n",
      "Total correct: 500\n",
      "Total accuracy for Slovak: 20.53%\n",
      "Languages Guessed: {'Lithuanian': 105, 'Czech': 55, 'Croatian': 688, 'Slovak': 500, 'Ukrainian': 83, 'Polish': 118, 'Slovene': 98, 'Serbian': 780, 'English': 8, 'Russian': 1}\n",
      "Most incorrectly guessed: Croatian\n",
      "Least incorrectly guessed: Russian\n",
      "Average characters until correct guess: 4.872\n",
      "\n",
      "\n",
      "Language: Slovene\n",
      "Total guesses: 1666\n",
      "Total correct: 500\n",
      "Total accuracy for Slovene: 30.01%\n",
      "Languages Guessed: {'Slovene': 500, 'Serbian': 360, 'Croatian': 486, 'Lithuanian': 55, 'Polish': 103, 'Slovak': 91, 'Czech': 24, 'Ukrainian': 47}\n",
      "Most incorrectly guessed: Croatian\n",
      "Least incorrectly guessed: Czech\n",
      "Average characters until correct guess: 3.332\n",
      "\n",
      "\n",
      "Language: Serbian\n",
      "Total guesses: 1325\n",
      "Total correct: 500\n",
      "Total accuracy for Serbian: 37.74%\n",
      "Languages Guessed: {'Serbian': 500, 'Croatian': 517, 'Lithuanian': 75, 'Slovene': 31, 'Slovak': 72, 'Czech': 14, 'Polish': 91, 'English': 1, 'Ukrainian': 24}\n",
      "Most incorrectly guessed: Serbian\n",
      "Least incorrectly guessed: English\n",
      "Average characters until correct guess: 2.65\n",
      "\n",
      "\n",
      "Language: Ukrainian\n",
      "Total guesses: 2347\n",
      "Total correct: 500\n",
      "Total accuracy for Ukrainian: 21.3%\n",
      "Languages Guessed: {'Lithuanian': 255, 'Croatian': 578, 'Ukrainian': 500, 'Serbian': 581, 'Slovene': 95, 'Polish': 107, 'Slovak': 173, 'English': 24, 'Czech': 34}\n",
      "Most incorrectly guessed: Croatian\n",
      "Least incorrectly guessed: English\n",
      "Average characters until correct guess: 4.694\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "further_analysis(language_stats, language_names, int2lang, language_names_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
